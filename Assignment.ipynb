{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP ASSIGNMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Jaccard Similarity/Similarity Coffiecient & Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the Inputs of Documents by which we have to compare our Query... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\WEBBWA~1\\AppData\\Local\\Temp/ipykernel_8748/1373130608.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mDoc_no\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter no of douments. : \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mDoc_lst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mDoc_Id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mDoc_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" Enter Contents of documents in Sentence form : \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "Doc_no = int(input(\"Enter no of douments. : \"))\n",
    "Doc_lst = []\n",
    "Doc_Id = []\n",
    "for _ in range (Doc_no):\n",
    "    doc = input(\" Enter Contents of documents in Sentence form : \")\n",
    "    Doc_lst.append(doc)\n",
    "    Doc_Id.append(_+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\"Id\":Doc_Id, \"Doc_Name\" : Doc_lst}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Doc_csv.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Doc_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Joe waited for the train.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The train was late.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mary and Samantha took the bus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I looked for Mary and Samantha at the bus stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mary and Samantha arrived at the bus station e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                           Doc_Name\n",
       "0   1                          Joe waited for the train.\n",
       "1   2                                The train was late.\n",
       "2   3                    Mary and Samantha took the bus.\n",
       "3   4  I looked for Mary and Samantha at the bus stat...\n",
       "4   5  Mary and Samantha arrived at the bus station e..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking Input of Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = Query = input(\"Enter The Query : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Id', 'Doc_Name'], ['1', 'Joe waited for the train.'], ['2', 'The train was late.'], ['3', 'Mary and Samantha took the bus.'], ['4', 'I looked for Mary and Samantha at the bus station.'], ['5', 'Mary and Samantha arrived at the bus station early but waited until noon for the bus.'], ['6', 'Joe waited for the train, but the train was late.'], ['7', 'I looked for Mary and Samantha at the bus station, but they arrived at the station before noon and left on the bus before I arrived.'], ['8', 'Mary and Samantha arrived at the bus station before noon, and they left on the bus before I arrived.'], ['9', 'Mary and Samantha left on the bus before I arrived, so I did not see them at the bus station.'], ['10', 'Because Mary and Samantha arrived at the bus station before noon, I did not see them at the station.']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"Doc_csv.csv\", newline=\"\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    lst = list(reader)\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', 'Joe waited for the train.'], ['2', 'The train was late.'], ['3', 'Mary and Samantha took the bus.'], ['4', 'I looked for Mary and Samantha at the bus station.'], ['5', 'Mary and Samantha arrived at the bus station early but waited until noon for the bus.'], ['6', 'Joe waited for the train, but the train was late.'], ['7', 'I looked for Mary and Samantha at the bus station, but they arrived at the station before noon and left on the bus before I arrived.'], ['8', 'Mary and Samantha arrived at the bus station before noon, and they left on the bus before I arrived.'], ['9', 'Mary and Samantha left on the bus before I arrived, so I did not see them at the bus station.'], ['10', 'Because Mary and Samantha arrived at the bus station before noon, I did not see them at the station.']]\n"
     ]
    }
   ],
   "source": [
    "lst.pop(0)\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram :  2\n"
     ]
    }
   ],
   "source": [
    "ngram = int(input(\"Enter the Valur of Ngram : \"))\n",
    "print(\"Ngram : \",ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Similarity Coefficient / Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sim_Coffecient(lst , Q, ngram):\n",
    "    Sim_Cof_list = []\n",
    "    Q = Q.lower()\n",
    "    for i in range (len(lst)):\n",
    "        sent = lst[i][1].lower()\n",
    "        d1 = []\n",
    "        d2 = []\n",
    "        counter = 0\n",
    "        for index in range(0,len(sent),ngram):\n",
    "            d1.append(sent[index:index+ngram])\n",
    "        for index in range(0,len(Q),ngram):\n",
    "            d2.append(Q[index:index+ngram])\n",
    "        d1 = list(set(d1))\n",
    "        d2 = list(set(d2))\n",
    "        if len(d1)<len(d2): \n",
    "            for x in range (len(d1)):\n",
    "                if d1[x] in d2:\n",
    "                    counter +=1\n",
    "        else : \n",
    "            for x in range(len(d2)):\n",
    "                if d2[x] in d1 :\n",
    "                    counter += 1    \n",
    "        Union = list(set(d1+d2))\n",
    "        Sim_cof = counter/len(Union)\n",
    "        Sim_Cof_list.append(Sim_cof*100)\n",
    "    d = {}\n",
    "    for e in range(len(lst)):\n",
    "        d[e+1] = Sim_Cof_list[e]\n",
    "        print( \"Similarity Coeffiecient Of Doc ID : \" , e+1, \" and the Query Given is : \", d[e+1],\"%\")\n",
    "    print()\n",
    "    print(\"With Maximum Similarity is : \", max(Sim_Cof_list),\"%\")\n",
    "    print(\"and Minimum Similarity of : \", min(Sim_Cof_list),\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cos_Coffecient(lst , Q, ngram):\n",
    "    Cosine_Cof_list = []\n",
    "    for i in range (len(lst)):\n",
    "        sent = lst[i][1]\n",
    "        d1 = sent.lower().split()\n",
    "        d2 = Q.lower().split()\n",
    "        counter = 0\n",
    "        \n",
    "        d1 = list(set(d1))\n",
    "        d2 = list(set(d2))\n",
    "        d3 = list(set(d1+d2))\n",
    "        counter1, counter2 = [], []\n",
    "        for x in d3:\n",
    "            c1, c2 = 0, 0\n",
    "            for y in d1:\n",
    "                if x == y:\n",
    "                    c1 += 1\n",
    "            for y in d2 :\n",
    "                if x == y:\n",
    "                    c2 += 1\n",
    "            counter1.append(c1)\n",
    "            counter2.append(c2)\n",
    "        Sum = 0\n",
    "        Root_C1 = 0\n",
    "        Root_C2 = 0\n",
    "        for q in range (len(counter1)):\n",
    "            Sum = Sum + (counter1[q]*counter2[q])\n",
    "            Root_C1 = Root_C1 + counter1[q]\n",
    "            Root_C2 = Root_C2 + counter2[q]\n",
    "        Root_C1 = Root_C1**0.5\n",
    "        Root_C2 = Root_C2**0.5\n",
    "        cosine_ = Sum / (Root_C1*Root_C2)\n",
    "        Cosine_Cof_list.append(cosine_*100)\n",
    "    d = {}\n",
    "    for e in range(len(lst)):\n",
    "        d[e+1] =(Cosine_Cof_list[e])\n",
    "        print( \"Cosine Similarity Of Doc ID : \" , e+1, \" and the Query Given is : \", d[e+1],\"%\")\n",
    "    print()\n",
    "    print(\"With Maximum Cosine Similarity is : \", max(Cosine_Cof_list),\"%\")\n",
    "    print(\"and Minimum Cosine Similarity of : \", min(Cosine_Cof_list),\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Of Doc ID :  1  and the Query Given is :  81.6496580927726 %\n",
      "Cosine Similarity Of Doc ID :  2  and the Query Given is :  40.8248290463863 %\n",
      "Cosine Similarity Of Doc ID :  3  and the Query Given is :  40.8248290463863 %\n",
      "\n",
      "With Maximum Cosine Similarity is :  81.6496580927726 %\n",
      "and Minimum Cosine Similarity of :  40.8248290463863 %\n",
      "\n",
      "Value Of Jaccard Similarity if We Are taking value of Ngram ( Shingles ) : 2\n",
      "\n",
      "Similarity Coeffiecient Of Doc ID :  1  and the Query Given is :  20.0 %\n",
      "Similarity Coeffiecient Of Doc ID :  2  and the Query Given is :  20.0 %\n",
      "Similarity Coeffiecient Of Doc ID :  3  and the Query Given is :  30.0 %\n",
      "\n",
      "With Maximum Similarity is :  30.0 %\n",
      "and Minimum Similarity of :  20.0 %\n"
     ]
    }
   ],
   "source": [
    "d1 = \"New York Times\"\n",
    "d2 = \"New York Post\"\n",
    "d3 = \"Los Angeles Times\"\n",
    "\n",
    "Q = \"New New Times\"\n",
    "\n",
    "ngram = 2\n",
    "\n",
    "lst = [[1,d1],[2,d2],[3,d3]]\n",
    "\n",
    "\n",
    "Cos_Coffecient(lst, Q, ngram)\n",
    "print()\n",
    "print(\"Value Of Jaccard Similarity if We Are taking value of Ngram ( Shingles ) : {}\".format(ngram))\n",
    "print()\n",
    "Sim_Coffecient(lst, Q, ngram)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bca7c2d3fe6349e52d1576f7ab066391be890b5e278ecfda5482677f5ebf6b3d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
